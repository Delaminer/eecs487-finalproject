{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test set annoy file to use for evaluation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "\n",
    "# Function to return mean reciprocal rank from the model for the given list of question ids and associated list of duplicate \"gold standard\" question ids\n",
    "# The score for an item in the question_ids list will be 1 if the first result given by the model matches the corresponding duplicate_ids item\n",
    "# Searches k top results for each question\n",
    "# Uses the basic BERT embedding from the helper.py file\n",
    "def get_mrr_and_accuracy(question_ids, duplicate_ids, k, annoy_test_set_filename):\n",
    "    mrr = 0.0\n",
    "    accuracy = 0.0\n",
    "    num_samples = len(questions)\n",
    "\n",
    "    for i in num_samples:\n",
    "        id = question_ids[i]\n",
    "        duplicate_id = duplicate_ids[i]\n",
    "        \n",
    "        question = get_question_body_from_id(id)\n",
    "        question_embedding = get_paragraph_embedding_bert(question)\n",
    "\n",
    "        u = AnnoyIndex(768, 'angular')\n",
    "        u.load(annoy_test_set_filename)\n",
    "        nearest_i = u.get_nns_by_vector(question_embedding, k) # will return the index of the k nearest neighbor\n",
    "\n",
    "        answer_rank = 0\n",
    "        try:\n",
    "            answer_rank = nearest_i.index(duplicate_id)\n",
    "        except ValueError:\n",
    "            # skip rest of iteration and don't update scores if the answer isn't found in the results\n",
    "            continue\n",
    "        \n",
    "        mrr += 1.0 / answer_rank\n",
    "        accuracy += 1 if answer_rank == 1.0 else 0\n",
    "        \n",
    "    mrr /= num_samples\n",
    "    accuracy /= num_samples\n",
    "    \n",
    "    return mrr, accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a seed \n",
    "# t.set_seed(487)\n",
    "# we need this to tell what the original sentences are \n",
    "\n",
    "# t.build(10) # build 10 trees, allegedly the more the better  \n",
    "# t.save('bert_embedding_unnormalize.ann')\n",
    "\n",
    "# Find k-nearest neighbor\n",
    "k = 3 # first set k = 5\n",
    "test_sentence = \"Why did Old English lose both thorn and eth?\" # one of the questions on linguistic stack exchange\n",
    "test_sentence_vector = encode_sentence(test_sentence)\n",
    "\n",
    "f = 768\n",
    "u = AnnoyIndex(f, 'angular')\n",
    "u.load('bert_embedding1.ann') \n",
    "nearest_i = u.get_nns_by_vector(test_sentence_vector, k) # will return the index of the k nearest neighbor\n",
    "nearest_word = [(i, questions[i]) for i in nearest_i] # \n",
    "nearest_word"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
