{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/alex/class/eecs487/eecs487-finalproject/model', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/alex/class/eecs487/eecs487-finalproject/.venv/lib/python3.10/site-packages', '..', '..']\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Performed tf-idf\n",
      "Special dataloader done processing.\n",
      "Keep in mind the data processed is in order, so you might want to shuffle them.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from collections import defaultdict\n",
    "\n",
    "from model import SpecialDataLoader\n",
    "\n",
    "special_dataloader = SpecialDataLoader(filepath=\"../dataset/dataset_subset4000.csv\")\n",
    "def c_to_d(c):\n",
    "    return special_dataloader.corpus_to_id[c]\n",
    "\n",
    "def d_to_c(d):\n",
    "    return special_dataloader.id_to_corpus[d]\n",
    "\n",
    "# split the data into train, test, and validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split train as 50%, val as 25%, test as 25% \n",
    "def get_training_splits(data):\n",
    "    X_train, X_test = train_test_split(\n",
    "        data.data, test_size = 0.25, random_state=487, shuffle=True \n",
    "    )\n",
    "\n",
    "    X_train, X_val = train_test_split(\n",
    "        X_train, test_size = 0.33, random_state=487, shuffle=True\n",
    "    )\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "# X_train, X_val, X_test = get_training_splits(data.data)\n",
    "\n",
    "special_X_train, special_X_val, special_X_test = get_training_splits(special_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9910x8176 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 76365 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_dataloader.matrix_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 When do I use \"can\" or \"could\"?\n",
      "4294 Correct usage of \"Could\" and \"Can\"\n"
     ]
    }
   ],
   "source": [
    "my_id = 1\n",
    "corpus_id = special_dataloader.id_to_corpus[my_id]\n",
    "print(my_id, special_dataloader.corpus[corpus_id])\n",
    "\n",
    "dup_id = special_dataloader.duplicate[my_id][0]\n",
    "print(dup_id,special_dataloader.corpus[special_dataloader.id_to_corpus[dup_id]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.12364144 0.18080016 ... 0.12468903 0.         0.07640815]]\n",
      "MY target of 4294 is rank 3 of 9910\n",
      "[  68 3184  228 ... 6178 6179    0]\n",
      "125481 Is it could or can?\n",
      "5902 When should we use \"can\", \"could\", \"will\", \"would\"?\n",
      "4294 Correct usage of \"Could\" and \"Can\"\n",
      "5552 When do I use \"me\" and when \"I\"?\n",
      "12458 How to use would or could in English?\n",
      "9434 When do I use the comma?\n",
      "103676 Can \"the least I could do\" be negative?\n",
      "133086 How can I use \"a\" with \"or\"\n",
      "182383 could be or could have been stolen?\n"
     ]
    }
   ],
   "source": [
    "# Find similar ones\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix = special_dataloader.matrix_X\n",
    "\n",
    "cos_similarities = cosine_similarity(matrix[special_dataloader.id_to_corpus[my_id]], matrix)\n",
    "print(cos_similarities)\n",
    "similar_doc_indices = cos_similarities.argsort()[0][::-1]\n",
    "def get_rank(corpus_id):\n",
    "    corpus_index = special_dataloader.id_to_corpus[corpus_id]\n",
    "    for rank, doc_index in enumerate(similar_doc_indices):\n",
    "        if doc_index == corpus_index:\n",
    "            return rank\n",
    "\n",
    "print(f\"MY target of {dup_id} is rank {get_rank(dup_id)} of {len(similar_doc_indices)}\")\n",
    "\n",
    "print(similar_doc_indices)\n",
    "for i in range(1, 10):\n",
    "    near_corpus_id = similar_doc_indices[i]\n",
    "    near_id = special_dataloader.corpus_to_id[similar_doc_indices[i]]\n",
    "    print(near_id, special_dataloader.corpus[near_corpus_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 5983 entries, MRR = 0.21827030274315945, Acc = 0.16195888350325924\n"
     ]
    }
   ],
   "source": [
    "# Get the MRR and accuracy\n",
    "mrr = 0.0\n",
    "num_correct = 0\n",
    "used = 0\n",
    "for this_doc_id in special_dataloader.duplicate.keys():\n",
    "    this_corpus_id = d_to_c(this_doc_id)\n",
    "\n",
    "    duplicates = special_dataloader.duplicate[this_doc_id]\n",
    "\n",
    "    # This doc_id has some duplicates\n",
    "    cos_similarities = cosine_similarity(matrix[this_corpus_id], matrix)\n",
    "    similar_corpus_indices = cos_similarities.argsort()[0][::-1]\n",
    "\n",
    "    # Get the rank of the closest duplicate\n",
    "    rank = -1\n",
    "    similar_doc_index = -1\n",
    "    for rank, similar_corpus_index in enumerate(similar_corpus_indices):\n",
    "        similar_doc_index = c_to_d(similar_corpus_index)\n",
    "        if similar_doc_index in duplicates:\n",
    "            break\n",
    "\n",
    "    # Note: normally, the top document (rank=0) is the question asked, and then duplicates follow, \n",
    "    # but sometimes the duplicate can take rank 0. If that's so, just account for that here:\n",
    "    if rank == 0:\n",
    "        rank = 1\n",
    "\n",
    "    if rank == 1:\n",
    "        num_correct += 1\n",
    "    mrr += 1.0 / rank\n",
    "n = len(special_dataloader.duplicate.keys())\n",
    "mrr /= n\n",
    "acc = num_correct / n\n",
    "print(f\"For {n} entries, MRR = {mrr}, Acc = {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
