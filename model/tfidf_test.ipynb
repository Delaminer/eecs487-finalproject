{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/alex/class/eecs487/eecs487-finalproject/model', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/alex/class/eecs487/eecs487-finalproject/.venv/lib/python3.10/site-packages', '..', '..', '..', '..', '..']\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "There are 9886 training and 2398 testing examples. Testing ratio = 0.19521328557473136 vs 0.2\n",
      "Performed tf-idf\n",
      "Special dataloader done processing.\n",
      "Keep in mind the data processed is in order, so you might want to shuffle them.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from collections import defaultdict\n",
    "\n",
    "from model import SpecialDataLoader\n",
    "\n",
    "# special_dataloader = SpecialDataLoader(filepath=\"../dataset/dataset.csv\")\n",
    "special_dataloader = SpecialDataLoader(filepath=\"../dataset/dataset_subset10000.csv\", testing_split=0.2)\n",
    "def c_to_d(c):\n",
    "    return special_dataloader.corpus_to_id[c]\n",
    "\n",
    "def d_to_c(d):\n",
    "    return special_dataloader.id_to_corpus[d]\n",
    "\n",
    "# split the data into train, test, and validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split train as 50%, val as 25%, test as 25% \n",
    "def get_training_splits(data):\n",
    "    X_train, X_test = train_test_split(\n",
    "        data.data, test_size = 0.25, random_state=487, shuffle=True \n",
    "    )\n",
    "\n",
    "    X_train, X_val = train_test_split(\n",
    "        X_train, test_size = 0.33, random_state=487, shuffle=True\n",
    "    )\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "# X_train, X_val, X_test = get_training_splits(data.data)\n",
    "\n",
    "special_X_train, special_X_val, special_X_test = get_training_splits(special_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12284x8233 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 93811 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_dataloader.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 When do I use \"can\" or \"could\"?\n",
      "4294 Correct usage of \"Could\" and \"Can\"\n"
     ]
    }
   ],
   "source": [
    "my_id = 1\n",
    "corpus_id = special_dataloader.id_to_corpus[my_id]\n",
    "print(my_id, special_dataloader.corpus[corpus_id])\n",
    "\n",
    "dup_id = special_dataloader.duplicate[my_id][0]\n",
    "print(dup_id,special_dataloader.corpus[special_dataloader.id_to_corpus[dup_id]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.12317498 0.18075553 ... 0.         0.         0.        ]]\n",
      "MY target of 4294 is rank 6 of 12284\n",
      "[  68 3184  228 ... 7655 7653    0]\n",
      "125481 Is it could or can?\n",
      "5902 When should we use \"can\", \"could\", \"will\", \"would\"?\n",
      "253426 \"Empty use\" of can and could\n",
      "182383 could be or could have been stolen?\n",
      "270478 How do I choose between \"can\" and \"could\"?\n",
      "4294 Correct usage of \"Could\" and \"Can\"\n",
      "58756 When do you use \"talked\" and \"spoke\"?\n",
      "5552 When do I use \"me\" and when \"I\"?\n",
      "12458 How to use would or could in English?\n"
     ]
    }
   ],
   "source": [
    "# Find similar ones\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "matrix = special_dataloader.matrix\n",
    "\n",
    "cos_similarities = cosine_similarity(matrix[special_dataloader.id_to_corpus[my_id]], matrix)\n",
    "print(cos_similarities)\n",
    "similar_doc_indices = cos_similarities.argsort()[0][::-1]\n",
    "def get_rank(corpus_id):\n",
    "    corpus_index = special_dataloader.id_to_corpus[corpus_id]\n",
    "    for rank, doc_index in enumerate(similar_doc_indices):\n",
    "        if doc_index == corpus_index:\n",
    "            return rank\n",
    "\n",
    "print(f\"MY target of {dup_id} is rank {get_rank(dup_id)} of {len(similar_doc_indices)}\")\n",
    "\n",
    "print(similar_doc_indices)\n",
    "for i in range(1, 10):\n",
    "    near_corpus_id = similar_doc_indices[i]\n",
    "    near_id = special_dataloader.corpus_to_id[similar_doc_indices[i]]\n",
    "    print(near_id, special_dataloader.corpus[near_corpus_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: For 5966 entries, MRR = 0.20549472943479663, Acc = 0.15085484411666109\n",
      "Testing: For 1429 entries, MRR = 0.19005409475919066, Acc = 0.13226032190342898\n"
     ]
    }
   ],
   "source": [
    "# Get the MRR and accuracy\n",
    "\n",
    "\n",
    "sections = [\n",
    "    (\"Training\", lambda x: not special_dataloader.is_doc_testing[x]),\n",
    "    (\"Testing\", lambda x: special_dataloader.is_doc_testing[x])\n",
    "]\n",
    "\n",
    "for name, critera in sections:\n",
    "    mrr = 0.0\n",
    "    num_correct = 0\n",
    "    used = 0\n",
    "    n = 0\n",
    "    for this_doc_id in special_dataloader.duplicate.keys():\n",
    "        if not critera(this_doc_id): # only iterate over training or testing IDs\n",
    "            continue\n",
    "        this_corpus_id = d_to_c(this_doc_id)\n",
    "\n",
    "        duplicates = special_dataloader.duplicate[this_doc_id]\n",
    "\n",
    "        # This doc_id has some duplicates\n",
    "        cos_similarities = cosine_similarity(matrix[this_corpus_id], matrix)\n",
    "        similar_corpus_indices = cos_similarities.argsort()[0][::-1]\n",
    "\n",
    "        # Get the rank of the closest duplicate\n",
    "        rank = -1\n",
    "        similar_doc_index = -1\n",
    "        for rank, similar_corpus_index in enumerate(similar_corpus_indices):\n",
    "            similar_doc_index = c_to_d(similar_corpus_index)\n",
    "            if similar_doc_index in duplicates:\n",
    "                break\n",
    "\n",
    "        # Note: normally, the top document (rank=0) is the question asked, and then duplicates follow, \n",
    "        # but sometimes the duplicate can take rank 0. If that's so, just account for that here:\n",
    "        if rank == 0:\n",
    "            rank = 1\n",
    "\n",
    "        if rank == 1:\n",
    "            num_correct += 1\n",
    "        mrr += 1.0 / rank\n",
    "        n += 1\n",
    "    # n = len(special_dataloader.duplicate.keys())\n",
    "    mrr /= n\n",
    "    acc = num_correct / n\n",
    "    print(f\"{name}: For {n} entries, MRR = {mrr}, Acc = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My question When do I use they instead of he or she?\n",
      "38250 User: She, He, She or He, or They?\n",
      "313 When do I use \"I\" instead of \"me?\"\n",
      "3127 When to use & instead of \"and\"\n",
      "154665 What to use instead of \"discardation\"?\n",
      "26721 Anyone: (\"they\" or \"he/she\") why is it sometimes plural?\n"
     ]
    }
   ],
   "source": [
    "# Find the duplicate question to this one\n",
    "# my_id = 1\n",
    "# this_text = special_dataloader.corpus[d_to_c(my_id)]\n",
    "# similar_text = \"When should I use can or could?\"\n",
    "\n",
    "# text = similar_text\n",
    "# Fit the data\n",
    "def get_nearest_questions(text, n=5):\n",
    "    row = special_dataloader.vectorizer.transform([text])\n",
    "\n",
    "    cos_similarities = cosine_similarity(row, matrix)\n",
    "    similar_corpus_indices = cos_similarities.argsort()[0][::-1]\n",
    "\n",
    "    top_corpus = similar_corpus_indices[:n]\n",
    "    top_responses = [(c_to_d(c), special_dataloader.corpus[c]) for c in top_corpus]\n",
    "    return top_responses\n",
    "\n",
    "my_text = \"When do I use they instead of he or she?\"\n",
    "answers = get_nearest_questions(my_text)\n",
    "print(\"My question\", my_text)\n",
    "for doc, text in answers:\n",
    "    print(doc, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
